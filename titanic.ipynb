{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# TODO: Add Cross-Validation for kernels","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.497802Z","iopub.execute_input":"2024-02-21T16:51:46.498296Z","iopub.status.idle":"2024-02-21T16:51:46.504225Z","shell.execute_reply.started":"2024-02-21T16:51:46.498264Z","shell.execute_reply":"2024-02-21T16:51:46.502722Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T16:51:46.509158Z","iopub.execute_input":"2024-02-21T16:51:46.509739Z","iopub.status.idle":"2024-02-21T16:51:46.530170Z","shell.execute_reply.started":"2024-02-21T16:51:46.509695Z","shell.execute_reply":"2024-02-21T16:51:46.528349Z"},"trusted":true},"execution_count":279,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.531796Z","iopub.execute_input":"2024-02-21T16:51:46.533057Z","iopub.status.idle":"2024-02-21T16:51:46.555652Z","shell.execute_reply.started":"2024-02-21T16:51:46.533007Z","shell.execute_reply":"2024-02-21T16:51:46.553367Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.559638Z","iopub.execute_input":"2024-02-21T16:51:46.560873Z","iopub.status.idle":"2024-02-21T16:51:46.569383Z","shell.execute_reply.started":"2024-02-21T16:51:46.560825Z","shell.execute_reply":"2024-02-21T16:51:46.568075Z"},"trusted":true},"execution_count":281,"outputs":[{"name":"stdout","text":"% of women who survived: 0.7420382165605095\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data['hasAge'] = ~train_data.Age.isna()\ntest_data['hasAge'] = ~test_data.Age.isna()\n\n# Initialize the MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\n# Fill NaNs without using inplace=True\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n\n# Fit and transform the data for training and testing datasets\ntrain_data['Age_normalized'] = scaler.fit_transform(train_data[['Age']].values.reshape(-1, 1))\ntest_data['Age_normalized'] = scaler.transform(test_data[['Age']].values.reshape(-1, 1))\n\n# Note: Use scaler.fit_transform() on the training data to fit the scaler and transform the data.\n# Use scaler.transform() on the test data to apply the same scaling based on the training data.","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.571723Z","iopub.execute_input":"2024-02-21T16:51:46.572261Z","iopub.status.idle":"2024-02-21T16:51:46.592942Z","shell.execute_reply.started":"2024-02-21T16:51:46.572227Z","shell.execute_reply":"2024-02-21T16:51:46.591267Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"# Initialize Fare Scaler\nfareScaler = MinMaxScaler(feature_range=(0,1))\n\n# Fill NaNs without using inplace=True\ntrain_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\n\n# Fit and transform the data for training and testing\ntrain_data['Fare'] = fareScaler.fit_transform(train_data[['Fare']].values.reshape(-1,1))\ntest_data['Fare'] = fareScaler.transform(test_data[['Fare']].values.reshape(-1,1))\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.594547Z","iopub.execute_input":"2024-02-21T16:51:46.595727Z","iopub.status.idle":"2024-02-21T16:51:46.639954Z","shell.execute_reply.started":"2024-02-21T16:51:46.595684Z","shell.execute_reply":"2024-02-21T16:51:46.638182Z"},"trusted":true},"execution_count":283,"outputs":[{"execution_count":283,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket      Fare Cabin Embarked  hasAge  Age_normalized  \n0      0         A/5 21171  0.014151   NaN        S    True        0.271174  \n1      0          PC 17599  0.139136   C85        C    True        0.472229  \n2      0  STON/O2. 3101282  0.015469   NaN        S    True        0.321438  \n3      0            113803  0.103644  C123        S    True        0.434531  \n4      0            373450  0.015713   NaN        S    True        0.434531  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>hasAge</th>\n      <th>Age_normalized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>0.014151</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>True</td>\n      <td>0.271174</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>0.139136</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>True</td>\n      <td>0.472229</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>0.015469</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>True</td>\n      <td>0.321438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>0.103644</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>True</td>\n      <td>0.434531</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>0.015713</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>True</td>\n      <td>0.434531</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import svm\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age_normalized\", \"Embarked\", \"Fare\", \"hasAge\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = svm.SVC()\nmodel.fit(X, y)\npredictions = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.641693Z","iopub.execute_input":"2024-02-21T16:51:46.642908Z","iopub.status.idle":"2024-02-21T16:51:46.705478Z","shell.execute_reply.started":"2024-02-21T16:51:46.642830Z","shell.execute_reply":"2024-02-21T16:51:46.703524Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"# CHECK FOR OVERFITTING\nfrom sklearn.metrics import accuracy_score\n\ntraining_predictions = model.predict(X)\ntraining_truth = y.to_numpy()\n\naccuracy = accuracy_score(training_truth, training_predictions)\nprint(f\"Accuracy:{accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.707403Z","iopub.execute_input":"2024-02-21T16:51:46.708407Z","iopub.status.idle":"2024-02-21T16:51:46.748173Z","shell.execute_reply.started":"2024-02-21T16:51:46.708368Z","shell.execute_reply":"2024-02-21T16:51:46.746465Z"},"trusted":true},"execution_count":285,"outputs":[{"name":"stdout","text":"Accuracy:0.8114478114478114\n","output_type":"stream"}]},{"cell_type":"code","source":"# CROSS-VALIDATION\n\n#pseudo-code\n'''\nfunc singleHyperTrain(train, test) # on a single folded set\n    declare optimalWeights (an array, perhaps)\n    CValues = [.001, .01, .1, 1, 10, 100, 1000]\n    for loop (loop through CValues)\n        create a model with ith hyperparams, fit it\n        check score on test set\n        if score is better than previous, record to optimalWeights\n    return optimalWeights\n    \nfunc crossTrain(data) # used to iterate through groups of data\n    # data is an object with 5 groups of dataframes\n    declare avgOptimalWeights\n    declre optimalWeightsArray\n    for i in data\n        notI = data except for i\n        localWeights = singleHyperTrain(notI, i)\n        add localWeights to optimalWeightsArray \n    avgOptimalWeights = avg(optimalWeightsArray)\n    return avgOptimalWeights\n    \nfiveGroups = np.array_split(train_data, 5)\nbestWeights = crossTrain(fiveGroups)\nprint(bestWeights)\n'''\n\ndef splitIntoGroups(data, numGroups):\n    df_shuffled = data.sample(frac=1, random_state=22).reset_index(drop=True)\n    groups = np.array_split(df_shuffled, 5)\n    return groups\n\ndef singleHyperTrain(train, test):\n    optimalWeights = []\n    CValues = [.001, .01, .1, 1, 10, 100, 1000]\n    kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n    for i in CValues:\n        for j in kernels:\n            y = train[\"Survived\"]\n            y_test = test[\"Survived\"]\n            features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age_normalized\", \"Embarked\", \"Fare\", \"hasAge\"]\n            X = pd.get_dummies(train[features])\n            X_test = pd.get_dummies(test[features])\n            model = svm.SVC(C=i, kernel=j)\n            model.fit(X, y)\n            predictions = model.predict(X_test)\n            accuracy = accuracy_score(y_test.to_numpy(), predictions)\n            print(f\"{accuracy} with C: {i}, kernel: {j}\")\n        \ndef crossTrain(data):\n    for i in range(0, len(data)):\n        trainGroup = pd.concat([groupsOfData[j] for j in range(len(groupsOfData)) if j != i])\n        singleHyperTrain(trainGroup, groupsOfData[i])\n    \n        \ngroupsOfData = splitIntoGroups(train_data, 5)\ncrossTrain(groupsOfData)\n# print(groupsOfData[1:])\n        ","metadata":{"execution":{"iopub.status.busy":"2024-02-21T16:51:46.752753Z","iopub.execute_input":"2024-02-21T16:51:46.753777Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0.6145251396648045 with C: 0.001, kernel: linear\n0.6145251396648045 with C: 0.001, kernel: poly\n0.6145251396648045 with C: 0.001, kernel: rbf\n0.6145251396648045 with C: 0.001, kernel: sigmoid\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"0.7486033519553073 with C: 0.01, kernel: linear\n0.7653631284916201 with C: 0.01, kernel: poly\n0.6145251396648045 with C: 0.01, kernel: rbf\n0.6145251396648045 with C: 0.01, kernel: sigmoid\n0.7486033519553073 with C: 0.1, kernel: linear\n0.7597765363128491 with C: 0.1, kernel: poly\n0.7486033519553073 with C: 0.1, kernel: rbf\n0.6983240223463687 with C: 0.1, kernel: sigmoid\n0.7486033519553073 with C: 1, kernel: linear\n0.770949720670391 with C: 1, kernel: poly\n0.7541899441340782 with C: 1, kernel: rbf\n0.6424581005586593 with C: 1, kernel: sigmoid\n0.7486033519553073 with C: 10, kernel: linear\n0.7877094972067039 with C: 10, kernel: poly\n0.7877094972067039 with C: 10, kernel: rbf\n0.6480446927374302 with C: 10, kernel: sigmoid\n0.7486033519553073 with C: 100, kernel: linear\n0.7877094972067039 with C: 100, kernel: poly\n0.7877094972067039 with C: 100, kernel: rbf\n0.6480446927374302 with C: 100, kernel: sigmoid\n0.7486033519553073 with C: 1000, kernel: linear\n0.776536312849162 with C: 1000, kernel: poly\n0.7932960893854749 with C: 1000, kernel: rbf\n0.6368715083798883 with C: 1000, kernel: sigmoid\n0.6348314606741573 with C: 0.001, kernel: linear\n0.6348314606741573 with C: 0.001, kernel: poly\n0.6348314606741573 with C: 0.001, kernel: rbf\n0.6348314606741573 with C: 0.001, kernel: sigmoid\n0.7752808988764045 with C: 0.01, kernel: linear\n0.702247191011236 with C: 0.01, kernel: poly\n0.6348314606741573 with C: 0.01, kernel: rbf\n0.6348314606741573 with C: 0.01, kernel: sigmoid\n0.7752808988764045 with C: 0.1, kernel: linear\n0.7640449438202247 with C: 0.1, kernel: poly\n0.8089887640449438 with C: 0.1, kernel: rbf\n0.7191011235955056 with C: 0.1, kernel: sigmoid\n0.7752808988764045 with C: 1, kernel: linear\n0.8089887640449438 with C: 1, kernel: poly\n0.8089887640449438 with C: 1, kernel: rbf\n0.6573033707865169 with C: 1, kernel: sigmoid\n0.7752808988764045 with C: 10, kernel: linear\n0.8033707865168539 with C: 10, kernel: poly\n0.8033707865168539 with C: 10, kernel: rbf\n0.6460674157303371 with C: 10, kernel: sigmoid\n0.7752808988764045 with C: 100, kernel: linear\n0.8089887640449438 with C: 100, kernel: poly\n0.8146067415730337 with C: 100, kernel: rbf\n0.6404494382022472 with C: 100, kernel: sigmoid\n0.7752808988764045 with C: 1000, kernel: linear\n0.8033707865168539 with C: 1000, kernel: poly\n0.7752808988764045 with C: 1000, kernel: rbf\n0.6404494382022472 with C: 1000, kernel: sigmoid\n0.651685393258427 with C: 0.001, kernel: linear\n0.651685393258427 with C: 0.001, kernel: poly\n0.651685393258427 with C: 0.001, kernel: rbf\n0.651685393258427 with C: 0.001, kernel: sigmoid\n0.7528089887640449 with C: 0.01, kernel: linear\n0.7078651685393258 with C: 0.01, kernel: poly\n0.651685393258427 with C: 0.01, kernel: rbf\n0.651685393258427 with C: 0.01, kernel: sigmoid\n0.7528089887640449 with C: 0.1, kernel: linear\n0.7528089887640449 with C: 0.1, kernel: poly\n0.7696629213483146 with C: 0.1, kernel: rbf\n0.7247191011235955 with C: 0.1, kernel: sigmoid\n0.7528089887640449 with C: 1, kernel: linear\n0.7696629213483146 with C: 1, kernel: poly\n0.7752808988764045 with C: 1, kernel: rbf\n0.6797752808988764 with C: 1, kernel: sigmoid\n0.7528089887640449 with C: 10, kernel: linear\n0.7865168539325843 with C: 10, kernel: poly\n0.7865168539325843 with C: 10, kernel: rbf\n0.6685393258426966 with C: 10, kernel: sigmoid\n0.7528089887640449 with C: 100, kernel: linear\n0.7921348314606742 with C: 100, kernel: poly\n0.7865168539325843 with C: 100, kernel: rbf\n0.6460674157303371 with C: 100, kernel: sigmoid\n","output_type":"stream"}]},{"cell_type":"code","source":"# CREATE PREDICTIONS\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}