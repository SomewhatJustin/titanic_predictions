{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c980deac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:21.602317Z",
     "iopub.status.busy": "2024-02-21T16:47:21.601734Z",
     "iopub.status.idle": "2024-02-21T16:47:21.609291Z",
     "shell.execute_reply": "2024-02-21T16:47:21.607977Z"
    },
    "papermill": {
     "duration": 0.018655,
     "end_time": "2024-02-21T16:47:21.612551",
     "exception": false,
     "start_time": "2024-02-21T16:47:21.593896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Cross-validation for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b450e9b6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:21.626292Z",
     "iopub.status.busy": "2024-02-21T16:47:21.625852Z",
     "iopub.status.idle": "2024-02-21T16:47:24.550079Z",
     "shell.execute_reply": "2024-02-21T16:47:24.548821Z"
    },
    "papermill": {
     "duration": 2.934415,
     "end_time": "2024-02-21T16:47:24.552797",
     "exception": false,
     "start_time": "2024-02-21T16:47:21.618382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ddc573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:24.565730Z",
     "iopub.status.busy": "2024-02-21T16:47:24.564363Z",
     "iopub.status.idle": "2024-02-21T16:47:24.599860Z",
     "shell.execute_reply": "2024-02-21T16:47:24.598231Z"
    },
    "papermill": {
     "duration": 0.045072,
     "end_time": "2024-02-21T16:47:24.602973",
     "exception": false,
     "start_time": "2024-02-21T16:47:24.557901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dfc3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:24.616290Z",
     "iopub.status.busy": "2024-02-21T16:47:24.615100Z",
     "iopub.status.idle": "2024-02-21T16:47:24.635978Z",
     "shell.execute_reply": "2024-02-21T16:47:24.634708Z"
    },
    "papermill": {
     "duration": 0.030511,
     "end_time": "2024-02-21T16:47:24.638883",
     "exception": false,
     "start_time": "2024-02-21T16:47:24.608372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of women who survived: 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ddf665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:24.652704Z",
     "iopub.status.busy": "2024-02-21T16:47:24.651342Z",
     "iopub.status.idle": "2024-02-21T16:47:24.673361Z",
     "shell.execute_reply": "2024-02-21T16:47:24.672117Z"
    },
    "papermill": {
     "duration": 0.032294,
     "end_time": "2024-02-21T16:47:24.676378",
     "exception": false,
     "start_time": "2024-02-21T16:47:24.644084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data['hasAge'] = ~train_data.Age.isna()\n",
    "test_data['hasAge'] = ~test_data.Age.isna()\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fill NaNs without using inplace=True\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n",
    "\n",
    "# Fit and transform the data for training and testing datasets\n",
    "train_data['Age_normalized'] = scaler.fit_transform(train_data[['Age']].values.reshape(-1, 1))\n",
    "test_data['Age_normalized'] = scaler.transform(test_data[['Age']].values.reshape(-1, 1))\n",
    "\n",
    "# Note: Use scaler.fit_transform() on the training data to fit the scaler and transform the data.\n",
    "# Use scaler.transform() on the test data to apply the same scaling based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02eed574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:24.689512Z",
     "iopub.status.busy": "2024-02-21T16:47:24.689083Z",
     "iopub.status.idle": "2024-02-21T16:47:24.729031Z",
     "shell.execute_reply": "2024-02-21T16:47:24.726972Z"
    },
    "papermill": {
     "duration": 0.050064,
     "end_time": "2024-02-21T16:47:24.732203",
     "exception": false,
     "start_time": "2024-02-21T16:47:24.682139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>hasAge</th>\n",
       "      <th>Age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.271174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>0.472229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.321438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.434531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0.434531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket      Fare Cabin Embarked  hasAge  Age_normalized  \n",
       "0      0         A/5 21171  0.014151   NaN        S    True        0.271174  \n",
       "1      0          PC 17599  0.139136   C85        C    True        0.472229  \n",
       "2      0  STON/O2. 3101282  0.015469   NaN        S    True        0.321438  \n",
       "3      0            113803  0.103644  C123        S    True        0.434531  \n",
       "4      0            373450  0.015713   NaN        S    True        0.434531  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Fare Scaler\n",
    "fareScaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Fill NaNs without using inplace=True\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\n",
    "\n",
    "# Fit and transform the data for training and testing\n",
    "train_data['Fare'] = fareScaler.fit_transform(train_data[['Fare']].values.reshape(-1,1))\n",
    "test_data['Fare'] = fareScaler.transform(test_data[['Fare']].values.reshape(-1,1))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d55c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:24.745800Z",
     "iopub.status.busy": "2024-02-21T16:47:24.745221Z",
     "iopub.status.idle": "2024-02-21T16:47:25.115171Z",
     "shell.execute_reply": "2024-02-21T16:47:25.113238Z"
    },
    "papermill": {
     "duration": 0.381,
     "end_time": "2024-02-21T16:47:25.118768",
     "exception": false,
     "start_time": "2024-02-21T16:47:24.737768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age_normalized\", \"Embarked\", \"Fare\", \"hasAge\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879db080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:25.133750Z",
     "iopub.status.busy": "2024-02-21T16:47:25.133217Z",
     "iopub.status.idle": "2024-02-21T16:47:25.169808Z",
     "shell.execute_reply": "2024-02-21T16:47:25.168040Z"
    },
    "papermill": {
     "duration": 0.048625,
     "end_time": "2024-02-21T16:47:25.173340",
     "exception": false,
     "start_time": "2024-02-21T16:47:25.124715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8114478114478114\n"
     ]
    }
   ],
   "source": [
    "# CHECK FOR OVERFITTING\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "training_predictions = model.predict(X)\n",
    "training_truth = y.to_numpy()\n",
    "\n",
    "accuracy = accuracy_score(training_truth, training_predictions)\n",
    "print(f\"Accuracy:{accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc90ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:25.190648Z",
     "iopub.status.busy": "2024-02-21T16:47:25.190235Z",
     "iopub.status.idle": "2024-02-21T16:47:28.388597Z",
     "shell.execute_reply": "2024-02-21T16:47:28.386383Z"
    },
    "papermill": {
     "duration": 3.211557,
     "end_time": "2024-02-21T16:47:28.392446",
     "exception": false,
     "start_time": "2024-02-21T16:47:25.180889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6145251396648045 with C: 0.001\n",
      "0.6145251396648045 with C: 0.01\n",
      "0.7486033519553073 with C: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541899441340782 with C: 1\n",
      "0.7877094972067039 with C: 10\n",
      "0.7877094972067039 with C: 100\n",
      "0.7932960893854749 with C: 1000\n",
      "0.7932960893854749 with C: 10000\n",
      "0.6348314606741573 with C: 0.001\n",
      "0.6348314606741573 with C: 0.01\n",
      "0.8089887640449438 with C: 0.1\n",
      "0.8089887640449438 with C: 1\n",
      "0.8033707865168539 with C: 10\n",
      "0.8146067415730337 with C: 100\n",
      "0.7752808988764045 with C: 1000\n",
      "0.7696629213483146 with C: 10000\n",
      "0.651685393258427 with C: 0.001\n",
      "0.651685393258427 with C: 0.01\n",
      "0.7696629213483146 with C: 0.1\n",
      "0.7752808988764045 with C: 1\n",
      "0.7865168539325843 with C: 10\n",
      "0.7865168539325843 with C: 100\n",
      "0.7808988764044944 with C: 1000\n",
      "0.7696629213483146 with C: 10000\n",
      "0.6235955056179775 with C: 0.001\n",
      "0.6235955056179775 with C: 0.01\n",
      "0.8314606741573034 with C: 0.1\n",
      "0.8258426966292135 with C: 1\n",
      "0.8314606741573034 with C: 10\n",
      "0.848314606741573 with C: 100\n",
      "0.8370786516853933 with C: 1000\n",
      "0.8202247191011236 with C: 10000\n",
      "0.5561797752808989 with C: 0.001\n",
      "0.5561797752808989 with C: 0.01\n",
      "0.8595505617977528 with C: 0.1\n",
      "0.848314606741573 with C: 1\n",
      "0.797752808988764 with C: 10\n",
      "0.8033707865168539 with C: 100\n",
      "0.7921348314606742 with C: 1000\n",
      "0.7808988764044944 with C: 10000\n"
     ]
    }
   ],
   "source": [
    "# CROSS-VALIDATION\n",
    "\n",
    "#pseudo-code\n",
    "'''\n",
    "func singleHyperTrain(train, test) # on a single folded set\n",
    "    declare optimalWeights (an array, perhaps)\n",
    "    CValues = [.001, .01, .1, 1, 10, 100, 1000]\n",
    "    for loop (loop through CValues)\n",
    "        create a model with ith hyperparams, fit it\n",
    "        check score on test set\n",
    "        if score is better than previous, record to optimalWeights\n",
    "    return optimalWeights\n",
    "    \n",
    "func crossTrain(data) # used to iterate through groups of data\n",
    "    # data is an object with 5 groups of dataframes\n",
    "    declare avgOptimalWeights\n",
    "    declre optimalWeightsArray\n",
    "    for i in data\n",
    "        notI = data except for i\n",
    "        localWeights = singleHyperTrain(notI, i)\n",
    "        add localWeights to optimalWeightsArray \n",
    "    avgOptimalWeights = avg(optimalWeightsArray)\n",
    "    return avgOptimalWeights\n",
    "    \n",
    "fiveGroups = np.array_split(train_data, 5)\n",
    "bestWeights = crossTrain(fiveGroups)\n",
    "print(bestWeights)\n",
    "'''\n",
    "\n",
    "def splitIntoGroups(data, numGroups):\n",
    "    df_shuffled = data.sample(frac=1, random_state=22).reset_index(drop=True)\n",
    "    groups = np.array_split(df_shuffled, 5)\n",
    "    return groups\n",
    "\n",
    "def singleHyperTrain(train, test):\n",
    "    optimalWeights = []\n",
    "    CValues = [.001, .01, .1, 1, 10, 100, 1000, 10000]\n",
    "    for i in CValues:\n",
    "        y = train[\"Survived\"]\n",
    "        y_test = test[\"Survived\"]\n",
    "        features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age_normalized\", \"Embarked\", \"Fare\", \"hasAge\"]\n",
    "        X = pd.get_dummies(train[features])\n",
    "        X_test = pd.get_dummies(test[features])\n",
    "        model = svm.SVC(C=i)\n",
    "        model.fit(X, y)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test.to_numpy(), predictions)\n",
    "        print(f\"{accuracy} with C: {i}\")\n",
    "        \n",
    "def crossTrain(data):\n",
    "    for i in range(0, len(data)):\n",
    "        trainGroup = pd.concat([groupsOfData[j] for j in range(len(groupsOfData)) if j != i])\n",
    "        singleHyperTrain(trainGroup, groupsOfData[i])\n",
    "    \n",
    "        \n",
    "groupsOfData = splitIntoGroups(train_data, 5)\n",
    "crossTrain(groupsOfData)\n",
    "# print(groupsOfData[1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3eb52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T16:47:28.409506Z",
     "iopub.status.busy": "2024-02-21T16:47:28.409091Z",
     "iopub.status.idle": "2024-02-21T16:47:28.424166Z",
     "shell.execute_reply": "2024-02-21T16:47:28.422010Z"
    },
    "papermill": {
     "duration": 0.026836,
     "end_time": "2024-02-21T16:47:28.427079",
     "exception": false,
     "start_time": "2024-02-21T16:47:28.400243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# CREATE PREDICTIONS\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.364887,
   "end_time": "2024-02-21T16:47:29.259780",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-21T16:47:17.894893",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
